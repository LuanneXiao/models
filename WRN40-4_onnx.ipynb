{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;\n",
    "import math;\n",
    "from PIL import Image\n",
    "import torch.onnx as torch_onnx\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型选择之前预测正确率最高的WRN40-4（dropout=0.5)模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WRN40-4 （dropout=0.5)模型\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv0 = nn.Conv2d(1,3,kernel_size=1,stride=1)   ##\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入已经训练好的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "cnn = WideResNet(40, 10, 4, 0.5)\n",
    "cnn.load_state_dict(torch.load('net_paramet_WRN_normalization.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入自定义图像，图像文件夹路径可更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 2 (C:/Users/15273/Desktop/figure\\fig1.jpg)\n",
      "Processing 2 of 2 (C:/Users/15273/Desktop/figure\\fig2.jpg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize(29),  #将图像的短边缩放成29个像素，长边按短边比例缩放\n",
    "    transforms.RandomCrop(28),  #随机裁剪成28*28\n",
    "    transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=[.2861], std=[.3530])  #mean和std采用与训练WRN网络时相同的取值\n",
    "    ])\n",
    "def get_files(directory):\n",
    "    return [os.path.join(directory, f) for f in sorted(list(os.listdir(directory)))\n",
    "            if os.path.isfile(os.path.join(directory, f))]\n",
    "images = np.array([])\n",
    "file = get_files('C:/Users/15273/Desktop/figure')\n",
    "for i, item in enumerate(file):\n",
    "    print('Processing %i of %i (%s)' % (i+1, len(file), item))\n",
    "    image = transform(PIL.ImageOps.invert(Image.open(item).convert('L')))\n",
    "    images = np.append(images, image.numpy())        \n",
    "img = images.reshape(-1, 1, 28, 28)\n",
    "img = torch.from_numpy(img).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示输入的自定义图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize(29),  #将图像的短边缩放成29个像素，长边按短边比例缩放\n",
    "    transforms.RandomCrop(28),  #随机裁剪成28*28\n",
    "    ])\n",
    "def get_files(directory):\n",
    "    return [os.path.join(directory, f) for f in sorted(list(os.listdir(directory)))\n",
    "            if os.path.isfile(os.path.join(directory, f))]\n",
    "images = np.array([])\n",
    "file1 = get_files('C:/Users/15273/Desktop/figure')\n",
    "for i, item in enumerate(file1):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    image = transform(Image.open(item))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对图像进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 0.1994764804840088 s\n",
      "tensor([[ 1.7932e+00, -2.7931e+00,  3.3836e-01, -6.8343e-02, -1.5870e+00,\n",
      "          1.7299e+00,  2.1492e+00, -2.2758e-03,  2.2609e-02, -1.5856e+00],\n",
      "        [-1.2890e+00,  2.5946e+00,  6.0274e-02,  3.4773e-01,  1.5576e+00,\n",
      "         -2.6403e+00, -1.3613e+00, -5.2097e-01, -3.6535e-01,  1.6132e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Predicted:  Shirt Trouser\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start=time.time()\n",
    "outputs = cnn(img)\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(outputs)\n",
    "classes = ('T-shirt', 'Trouser', 'Pollover', 'Dress',\n",
    "           'Coat', 'Sandal', 'Shirt','Sneaker', 'Bag', 'Ankle boot')\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
